from flask import Flask, request, render_template, jsonify
import pickle
import os
import pdfplumber
from io import BytesIO
from app.preprocess import preprocessing_text  

app = Flask(__name__)

# Paths
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MODEL_DIR = os.path.join(BASE_DIR, "models")

# Load model files generated by main.py
cv = pickle.load(open(os.path.join(MODEL_DIR, "count_vectorizer.pkl"), "rb"))
tfidf_transformer = pickle.load(open(os.path.join(MODEL_DIR, "tfidf_transformer.pkl"), "rb"))
feature_names = pickle.load(open(os.path.join(MODEL_DIR, "features_names.pkl"), "rb"))


# ---------------- PDF TEXT EXTRACTION ----------------
def extract_pdf_text(pdf_bytes):
    """Extracts text from a PDF file using pdfplumber."""
    full_text = ""
    with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:
        for page in pdf.pages:
            text = page.extract_text() or ""
            full_text += text + "\n"
    return full_text.strip()


# ---------------- KEYWORD EXTRACTION ----------------
def extract_keywords(text, topN=1):
    processed = preprocessing_text(text)

    # TF-IDF transform
    tfidf_matrix = tfidf_transformer.transform(cv.transform([processed])).tocoo()

    # Sort by score
    tuples = zip(tfidf_matrix.col, tfidf_matrix.data)
    sorted_items = sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)

    sorted_items = sorted_items[:topN]

    keywords = []
    for idx, score in sorted_items:
        keywords.append({
            "word": feature_names[idx],
            "score": round(float(score), 3)
        })

    return keywords


# ---------------- ROUTES ----------------
@app.route("/")
def index():
    return render_template("index.html")


@app.route("/extract", methods=["POST"])
def extract():
    pdf_files = request.files.getlist("pdf_file")
    text_input = request.form.get("text_input", "")
    top_k = int(request.form.get("top_k", 1))

    results = []

    # Process PDF files
    for pdf in pdf_files:
        extracted_text = extract_pdf_text(pdf.read())
        keywords = extract_keywords(extracted_text, top_k)

        results.append({
            "filename": pdf.filename,
            "keywords": keywords
        })

    # Process manual text
    if text_input.strip():
        keywords = extract_keywords(text_input, top_k)
        results.append({
            "filename": "Typed Text",
            "keywords": keywords
        })

    return jsonify({"results": results})


@app.route("/api/extract", methods=["POST"])
def api_extract():
    data = request.get_json()
    text = data.get("text", "")
    top_k = int(data.get("top_k", 1))

    keywords = extract_keywords(text, top_k)
    return jsonify(keywords)


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
    # app.run(debug=True)
